---
title: "Quick start guide"
author: "Dax Kellie"
date: '2024-12-12'
output: 
  rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Quick start guide}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
resource_files:
  - './westerband_2022_wdate.csv'
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

corella is a tool for standardising data in R to use the [*Darwin Core standard*](https://www.gbif.org/darwin-core). Darwin Core standard is the primary data standard for species occurrence data---records of organisms observed in a location and time---in the [Atlas of Living Australia (ALA)](https://ala.org.au/), other [Living Atlases](https://living-atlases.gbif.org/) and the [Global Biodiversity Information Facility (GBIF)](https://www.gbif.org/). The standard allows the ability to compile data from a variety of sources, improving the ease to share, use and reuse data.

The main tasks to standardise data with Darwin Core standard are:

  1. Ensure columns use valid Darwin Core terms as column names
  2. Include all required information (e.g. scientific name, unique observation ID, valid date)
  3. Ensure columns contain valid data

This process can be daunting. corella is designed to reduce confusion of how to get started, and help determine which Darwin Core terms might match your column names.

# Install

To install from CRAN:

```{r}
#| eval: false
install.packages("corella")
```

To install the development version from GitHub:

```{r}
#| eval: false
#| message: false
#| warning: false
# install.packages("devtools")
devtools::install_github("AtlasOfLivingAustralia/corella")
```

To load the package:

```{r}
library(corella)
```


# Rename, add or edit columns

Here is a minimal example dataset of cockatoo observations. In our dataframe `df` there are columns that contain information that we would like to standardise using Darwin Core.

```{r}
#| code-fold: true
#| 
library(tibble)
library(lubridate)

df <- tibble(
  latitude = c(-35.310, "-35.273"), # deliberate error for demonstration purposes
  longitude = c(149.125, 149.133),
  date = c("14-01-2023", "15-01-2023"),
  time = c("10:23:00", "11:25:00"),
  month = c("January", "February"),
  day = c(100, 101),
  species = c("Callocephalon fimbriatum", "Eolophus roseicapilla"),
  n = c(2, 3),
  crs = c("WGS84", "WGS8d"),
  country = c("Australia", "Denmark"),
  continent = c("Oceania", "Europe")
  )
```


```{r}
df
```

We can standardise our data with `set_` functions. The `set_` functions possess a suffix name to identify what type of data they are used to standardise (e.g. `set_coordinates`, `set_datetime`), and arguments in `set_` functions are valid Darwin Core *terms* (ie column names). By grouping Darwin Core terms based on their data type, corella makes it easier for users to find relevant Darwin Core terms to use as column names (one of the most onerous parts of Darwin Core for new users).

Let's specify that the scientific name (i.e. genus + species name) in our data is in the `species` column by using `set_scientific_name()`. You'll notice 2 things happen:

  1. The `species` column in our dataframe is renamed to `scientificName`
  2. `set_scientific_name()` runs a check on our `species` column to make sure it is formatted correctly

```{r}
df |>
  set_scientific_name(scientificName = species)
```


What happens when we add a column with an error in it? The `latitude` column in `df` is a class `character` column, instead of a `numeric` column as it should be. When we try to update the column name using `set_coordinates()`, an error tells us the class is wrong.

```{r}
#| eval: true
#| error: true
df |>
  set_scientific_name(scientificName = species) |>
  set_coordinates(decimalLongitude = longitude,
                  decimalLatitude = latitude)
```


## Fix or update columns

To change, edit or fix a column, users can edit the column within the `set_` function.

Each `set_` function is essentially a specialised [`dplyr::mutate()`](https://dplyr.tidyverse.org/reference/mutate.html), meaning users can edit columns using the same processes they would when using `dplyr::mutate()`. We can fix the `latitude` column so that it is class `numeric` within the `set_coordinates()` function.

```{r}
df_darwincore <- df |>
  set_scientific_name(scientificName = species) |>
  set_coordinates(decimalLongitude = longitude,
                  decimalLatitude = as.numeric(latitude))

df_darwincore
```

## Auto-detect columns

corella is also able to detect when a column exists in a data frame that already has a valid Darwin Core term as a column name. For example, `df` contains columns with locality information. We can add `set_locality()` to our pipe to identify these columns, but because several columns already have valid Darwin Core terms as column names (`country` and `continent`), `set_locality()` will detect these valid Darwin Core columns in `df` and check them automatically.

```{r}
df |>
  set_scientific_name(scientificName = species) |>
  set_coordinates(decimalLongitude = longitude,
                  decimalLatitude = as.numeric(latitude)) |>
  set_locality()

df_darwincore
```

corella's auto-detection prevents users from needing to specify every single column, reducing the amount of typing for users when they have already have valid Darwin Core column names!


# Suggest a workflow

Unsure where to start? Confused about the minimum requirements to share your data? Using `suggest_workflow()` is the easiest way to get started in corella.

`suggest_workflow()` provides a high level summary designed to show:

  1. Which column names match valid Darwin Core terms
  2. The minimum requirements for data in a [Darwin Core Archive](https://support.ala.org.au/support/solutions/articles/6000261427-sharing-a-dataset-with-the-ala#create-archive) (i.e. a completed data resource in Darwin Core standard).
  3. A suggested workflow to help you add the minimum required columns
  4. Additional functions that could be added to a piped workflow (based the provided dataset's matching Darwin Core column names)
  
The intention of `suggest_workflow()` is to provide a general help function whenever users feel uncertain about what to do next. Let's see what the output says about our original dataframe `df`.

```{r}
df |>
  suggest_workflow()
```

`suggest_workflow()` will update the suggested function pipe to only suggest functions that are necessary to standardise your data correctly. 

For example, after using one of the suggested functions `set_occurrences()`, if we run `suggest_workflow()` again, the output message no longer suggests `set_occurrences()`. 

```{r}
#| message: false
#| warning: false
#| error: false
df_edited <- df |>
  set_occurrences(
    occurrenceID = seq_len(nrow(df)),
    basisOfRecord = "humanObservation"
    )
```

```{r}
df_edited |>
  suggest_workflow()
```

# Test your data

If your dataset already uses valid Darwin Core terms as column names, instead of working through each `set_` function, you might wish to run tests on your entire dataset. To run checks on your data like a test suite, use `check_dataset()`. Much like `devtools::test()` or `devtools::check()`, `check_dataset()` runs the relevant check on each matching Darwin Core column and returns a summary of the results, along with any error messages returned by those checks.

```{r}
df <- tibble(
  latitude = c(-35.310, "-35.273"), # deliberate error for demonstration purposes
  longitude = c(149.125, 149.133),
  date = c("14-01-2023", "15-01-2023"),
  individualCount = c(0, 2),
  species = c("Callocephalon fimbriatum", "Eolophus roseicapilla"),
  country = c("AU", "AU"),
  occurrenceStatus = c("present", "present")
  )

df |>
  check_dataset()
```


# `set_measurements`: a work in progress

Let's use a small sample of a real dataset of Australian native plant species (e.g. Eucalypts and Acacias). The dataset contains lots of columns containing measurements that capture the traits or environment of each species occurrence. I have extracted 3 examples of these measurement columns: `LMA_g.m2`, `LeafN_area_g.m2`, `PNUE`.

```{r}
#| warning: false
#| message: false
library(tibble)
library(readr)
library(dplyr)
library(tidyr)

# take a small sample
df_filtered <- read.csv("./westerband_2022_wdate.csv") |>
  select(Site, Species, Latitude, Longitude, LMA_g.m2, LeafN_area_g.m2, PNUE)

df_filtered |> head(10L) # see first 10 rows
```


The way that Darwin Core handles measurement fields is slightly different to how they are organised in these data. In `df_filtered`, lots of information about what data the column contains is in the abbreviated column name. This includes the type of measure, the unit it is measured in, and the value itself. In Darwin Core, this information needs to be documented individually for each measurement, which requires multiple columns and multiple rows (ie a 'long' data format). 

corella can convert measurement columns into Darwin Core standard with `set_measurements()`. This function requires users to specify the column, unit and measure type for each respective measurement. `set_measurements()` then assigns this information to the correct Darwin Core columns, and nests these columns into a nested column called `measurementOrFact`. 

```{r, message=FALSE, warning=FALSE}
df_nested <- df_filtered |>
  slice(220:270) |>
  set_measurements(cols = c(LMA_g.m2, 
                            LeafN_area_g.m2, 
                            PNUE),
                   unit = c("g/m2", 
                            "g/m2", 
                            "co2/s"),
                   type = c("leaf mass per area", 
                            "leaf nitrogen per area", 
                            "photosynthetic nitrogen use efficiency")
                   )


df_nested |> slice(1:3)
```


This nested structure allows the newly formatted information (now in long format) to still link correctly to each species occurrence. To view or access this now-standardised long-format data, use `dplyr::unnest()`.

```{r}
df_nested |>
  unnest(measurementOrFact)
```

